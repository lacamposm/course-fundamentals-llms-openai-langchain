{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sHqfwjHTrPVe"
   },
   "source": [
    "---\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://github.com/lacamposm/course-fundamentals-llms-openai-langchain/raw/main/images/image_igac.jpg\" alt=\"Imagen_IGAC\" width=\"280\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CcolQEVcoqh7"
   },
   "source": [
    "---\n",
    "\n",
    "# ***Fundamentos de LLMs con Python: Explorando ChatGPT y LangChain***\n",
    "\n",
    "---\n",
    "\n",
    "#### ***Instructor: [Luis Andrés Campos Maldonado](https://www.linkedin.com/in/lacamposm/)***\n",
    "\n",
    "##### ***Email: luisandres.campos@igac.gov.co***\n",
    "\n",
    "##### ***Contratista-Observatorio Inmobiliario Catastral***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdTcl3zMr7OA"
   },
   "source": [
    "---\n",
    "\n",
    "# ***Clase 07 - 12 de abril de 2024***\n",
    "---\n",
    "\n",
    "## ***Implementando memoria en Chatbots con LangChain y Streamlit***\n",
    "\n",
    "**Objetivos de Aprendizaje:**\n",
    "\n",
    "- Introducir el concepto de memoria en las interacciones con modelos de lenguaje como ChatGPT.\n",
    "- Demostrar cómo implementar y gestionar memoria en un chatbot.\n",
    "- Utilizar [Streamlit](https://streamlit.io/) para crear una interfaz de usuario simple para el chatbot, enfocándose en la funcionalidad de memoria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Concepto de Memoria en LangChain***\n",
    "\n",
    "Un componente esencial en muchas aplicaciones basadas en inteligencia artificial generativa, es que tienen interfaces conversacionales, es decir, tiene la capacidad de referirse a información introducida anteriormente en la conversación. A esto, en LangChain, se le llama \"memory\" (memoria).\n",
    "\n",
    "###  ***Introducción a la Memoria en LangChain***\n",
    "\n",
    "La memoria en LangChain permite a un sistema conversacional acceder a una ventana de mensajes pasados directamente, o incluso mantener un modelo del mundo que actualiza constantemente, lo cual le permite mantener información sobre entidades y sus relaciones. Esto se logra a través de dos acciones básicas: leer (READ) y escribir (WRITE).\n",
    "\n",
    "\n",
    "### ***Cómo Funciona la Memoria***\n",
    "\n",
    "1. **Lectura (READ):** Antes de ejecutar la lógica central, el sistema lee de su sistema de memoria y complementa las entradas de usuario.\n",
    "2. **Escritura (WRITE):** Después de ejecutar la lógica central pero antes de devolver la respuesta, el sistema escribe las entradas y salidas del ciclo actual en la memoria, para que puedan ser referenciadas en ciclos futuros.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://github.com/lacamposm/course-fundamentals-llms-openai-langchain/raw/main/images/memory_langchain.png\" alt=\"Imagen_IGAC\" width=\"900\" height=\"450\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install pandas openpyxl langchain openai langchain-openai langchain-community langchain-core langchain-text-splitters chromadb pypdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Construyendo Memoria en un Sistema***\n",
    "\n",
    "La construcción de la memoria en un sistema implica dos decisiones de diseño clave:\n",
    "\n",
    "- **Cómo se almacena el estado:** LangChain ofrece integraciones para almacenar mensajes de chat, desde listas en memoria hasta bases de datos persistentes.\n",
    "- **Cómo se consulta el estado:** Sobre los mensajes de chat almacenados, se pueden construir estructuras de datos y algoritmos que ofrezcan una vista útil de esos mensajes, desde sistemas simples que solo retornan los mensajes más recientes hasta sistemas más sofisticados que extraen y retornan información sobre entidades específicas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Ejemplo Práctico con `ConversationBufferMemory`***\n",
    "\n",
    "`ConversationBufferMemory` en LangChain representa una implementación sencilla y directa de la gestión de memoria en aplicaciones conversacionales. Este tipo de memoria se centra en almacenar una lista de mensajes de chat en un búfer, que luego se pueden utilizar para influir en las respuestas generadas por modelos de lenguaje. Su funcionalidad clave radica en su capacidad para retener un registro de la interacción entre el usuario y el sistema, proporcionando un contexto conversacional que mejora la coherencia y relevancia de las respuestas del sistema. La utilización de esta herramienta es particularmente beneficiosa en escenarios donde la continuidad de la conversación y la relevancia contextual son cruciales para la experiencia del usuario. En bots de servicio al cliente, la capacidad de referirse a interacciones anteriores en tiempo real mejora significativamente la interacción usuario-máquina."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***Asistente de Recomendación de Películas:***\n",
    "\n",
    "El usuario interactuará con un asistente que le recomienda películas basándose en las preferencias expresadas en la conversación. La memoria del asistente recordará los géneros de películas mencionados anteriormente para ajustar sus recomendaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Hola, ¿me recomiendas una película?\\nAI: ¡Claro! ¿Qué género prefieres?\\nHuman: Me gustan las películas de ciencia ficción.'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "# El usuario saluda y muestra interés en una recomendación, agregamos mensajes.\n",
    "memory.chat_memory.add_user_message(\"Hola, ¿me recomiendas una película?\")\n",
    "memory.chat_memory.add_ai_message(\"¡Claro! ¿Qué género prefieres?\")\n",
    "# El usuario responde con su preferencia.\n",
    "memory.chat_memory.add_user_message(\"Me gustan las películas de ciencia ficción.\")\n",
    "# Aquí, 'history' se carga desde la memoria y se espera que el cadena (y probablemente el promtp) \n",
    "# acepte una entrada con este nombre.\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basándonos en el historial almacenado, el sistema podría generar una recomendación personalizada. Aunque en este ejemplo no integraremos un LLM (e.g ChatOpenAI), podemos simular una lógica de respuesta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Te recomiendo ver 'Interstellar', es una gran película de ciencia ficción.\n"
     ]
    }
   ],
   "source": [
    "# Cargamos las variables de memoria antes de generar la siguiente respuesta\n",
    "memory_variables = memory.load_memory_variables({})\n",
    "\n",
    "if \"ciencia ficción\" in memory_variables[\"history\"]:\n",
    "    print(\"Te recomiendo ver 'Interstellar', es una gran película de ciencia ficción.\")\n",
    "else:\n",
    "    print(\"¿Tienes algún género favorito?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Ejemplo: Parámetros con `ConversationBufferMemory`***\n",
    "\n",
    "`ConversationBufferMemory` ofrece opciones configurables a través de sus parámetros, permitiendo adaptar el comportamiento de la memoria a las necesidades específicas de la aplicación.\n",
    "- ***memory_key***: Este parámetro determina la clave bajo la cual se almacenarán y recuperarán las variables de memoria. Es fundamental para asegurar que los datos de memoria se sincronicen correctamente con los prompts del modelo de lenguaje, facilitando así la generación de respuestas contextualizadas.\n",
    "\n",
    "- ***return_messages***: Este parámetro controla el formato en el que se retornan los mensajes almacenados en la memoria. Al configurarlo como True, se indica que los mensajes deben retornarse como una lista de objetos ChatMessage, en lugar de un único string concatenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='Hola, ¿me recomiendas una película?'),\n",
       "  AIMessage(content='¡Claro! ¿Qué género prefieres?')]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"chat_history\" como key. El historial de chat será accesible bajo esta denominación para su uso en la generación de prompts.\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "memory.chat_memory.add_user_message(\"Hola, ¿me recomiendas una película?\")\n",
    "memory.chat_memory.add_ai_message(\"¡Claro! ¿Qué género prefieres?\")\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Ejemplo: Usando `ConversationBufferWindowMemory`***\n",
    "\n",
    "`ConversationBufferWindowMemory` en LangChain mejora las capacidades de manejo de memoria en aplicaciones conversacionales mediante la implementación de una ventana deslizante. Está diseñada para retener únicamente las últimas $k$ interacciones de la conversación, lo que permite limitar el tamaño del búfer y gestionar de manera más eficiente el contexto conversacional. Al utilizar sólo las interacciones recientes, se ayuda a reducir el número de tokens procesados, optimizando el rendimiento sin comprometer significativamente la relevancia del contexto.\n",
    "\n",
    "Claves:\n",
    "\n",
    "1. ***Ventana Deslizante:*** Almacena solo las últimas $k$ interacciones, proporcionando un enfoque práctico para manejar conversaciones largas sin sobrecargar la memoria del sistema.\n",
    "2. ***Pérdida de Contexto:*** Aunque este enfoque puede perder el contexto de interacciones que preceden a las últimas K entradas, es un compromiso útil para mantener la eficiencia en conversaciones extensas o altamente dinámicas.\n",
    "3. ***Gestión de Tokens:*** Reduce la carga computacional al limitar el número de tokens que el modelo de lenguaje necesita procesar en cada interacción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Chatbot de Soporte Técnico.***\n",
    "\n",
    "Supongamos que estamos desarrollando un chatbot de soporte técnico que utiliza `ConversationBufferWindowMemory` para gestionar las interacciones con los usuarios. Este bot ayuda a los usuarios a solucionar problemas técnicos, y es crucial que recuerde las interacciones recientes para proporcionar soluciones coherentes sin retener toda la historia de la conversación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='Sí, y sigue sin funcionar.'),\n",
       "  AIMessage(content='¿Puedes verificar si la luz del cable de alimentación está encendida?'),\n",
       "  HumanMessage(content='La luz está apagada.'),\n",
       "  AIMessage(content='Parece que el problema podría estar en el cable de alimentación. ¿Tienes otro que puedas probar?')]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(memory_key=\"chat_history\", k=2, return_messages=True)\n",
    "\n",
    "## Otra manera de introduccir los mensajes a la memoria.\n",
    "memory.save_context({\"input\": \"Mi computadora no enciende.\"}, {\"output\": \"¿Has intentado conectarla a otra toma de corriente?\"})\n",
    "\n",
    "memory.chat_memory.add_user_message(\"Sí, y sigue sin funcionar.\")\n",
    "memory.chat_memory.add_ai_message(\"¿Puedes verificar si la luz del cable de alimentación está encendida?\")\n",
    "memory.chat_memory.add_user_message(\"La luz está apagada.\")\n",
    "memory.chat_memory.add_ai_message(\"Parece que el problema podría estar en el cable de alimentación. ¿Tienes otro que puedas probar?\")\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Ejemplo: `ConversationSummaryMemory`***\n",
    "\n",
    "Es un tipo de memoria más avanzado en LangChain diseñado para aplicaciones conversacionales que requieren la condensación de información a lo largo del tiempo. Esta memoria es especialmente útil para conversaciones prolongadas donde mantener un historial completo de mensajes en la entrada del modelo ocuparía demasiados tokens. `ConversationSummaryMemory` genera un resumen continuo de la conversación, almacenando y actualizando un sumario que puede ser inyectado en los prompts o cadenas para influir en las respuestas subsiguientes. Esta capacidad de resumir permite mantener relevante y compacto el contexto conversacional, optimizando el uso de recursos computacionales y mejorando la coherencia de las interacciones.\n",
    "\n",
    "Características:\n",
    "\n",
    "1. ***Generación de Resumen Dinámico:*** Automáticamente resume la conversación a medida que ocurre, proporcionando un contexto condensado pero comprensivo.\n",
    "2. ***Optimización del Uso de Tokens:*** Al reducir la longitud del contexto que se pasa a los modelos de lenguaje, se minimiza el número de tokens necesarios, lo cual es crucial para limitar los costos y mejorar la eficiencia en modelos basados en tokens.\n",
    "3. ***Aplicabilidad en Conversaciones Largas:*** Ideal para diálogos extendidos donde retener cada mensaje sería impracticable debido a las restricciones de longitud de entrada de los modelos de lenguaje modernos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Ejemplo: Implementación de memoria con LangChain y ChatOpenAI***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una variable de entorno para la API KEY de OpenAI.\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<YOUR_API_KEY>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Eres un buen chatbot teniendo una conversación con un humano. Debes recordar el nombre del humano si es dado.\n",
      "Human: Hola me llamo Andres Campos, como estas?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'user_message': 'Hola me llamo Andres Campos, como estas?',\n",
       " 'text': 'Hola, Andrés Campos. ¡Yo estoy bien, gracias! ¿Cómo estás tú? ¿En qué puedo ayudarte hoy?'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate.from_template(\n",
    "            \"Eres un buen chatbot teniendo una conversación con un humano. Debes recordar el nombre del humano si es dado.\"\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"{user_message}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "\n",
    "llm.invoke({\"user_message\": \"Hola me llamo Andres Campos, como estas?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Eres un buen chatbot teniendo una conversación con un humano. Debes recordar el nombre del humano si es dado.\n",
      "Human: ¿Cual es mi nombre?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'user_message': '¿Cual es mi nombre?',\n",
       " 'text': 'Lo siento, pero como soy un programa de inteligencia artificial, no tengo la capacidad de recordar información personal sobre los usuarios. ¿Hay algo más en lo que pueda ayudarte?'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No tiene memoria!.\n",
    "llm.invoke(\"¿Cual es mi nombre?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Implementación de memoria con LangChain.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora con memoria.\n",
    "llm = ChatOpenAI()\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate.from_template(\n",
    "            \"Eres un buen chatbot teniendo una conversación con un humano.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{user_message}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Observe que `return_messages=True` y `\"chat_history\"` encaja en MessagesPlaceholder via `variable_name=chat_history`\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "conversation = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Eres un buen chatbot teniendo una conversación con un humano.\n",
      "Human: Hola, me llamo Andres Campos, Me recomiendas una película por favor.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'user_message': 'Hola, me llamo Andres Campos, Me recomiendas una película por favor.',\n",
       " 'chat_history': [HumanMessage(content='Hola, me llamo Andres Campos, Me recomiendas una película por favor.'),\n",
       "  AIMessage(content='¡Hola, Andrés! Claro que sí, ¿qué tipo de películas te gustan? ¿Prefieres algún género en particular o tienes alguna película favorita que te pueda ayudar a recomendarte algo similar? ¡Cuéntame un poco más para poder sugerirte una película adecuada para ti!')],\n",
       " 'text': '¡Hola, Andrés! Claro que sí, ¿qué tipo de películas te gustan? ¿Prefieres algún género en particular o tienes alguna película favorita que te pueda ayudar a recomendarte algo similar? ¡Cuéntame un poco más para poder sugerirte una película adecuada para ti!'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke({\"user_message\": \"Hola, me llamo Andres Campos, Me recomiendas una película por favor.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Eres un buen chatbot teniendo una conversación con un humano.\n",
      "Human: Hola, me llamo Andres Campos, Me recomiendas una película por favor.\n",
      "AI: ¡Hola, Andrés! Claro que sí, ¿qué tipo de películas te gustan? ¿Prefieres algún género en particular o tienes alguna película favorita que te pueda ayudar a recomendarte algo similar? ¡Cuéntame un poco más para poder sugerirte una película adecuada para ti!\n",
      "Human: Me gustan las películas de ciencia ficción.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'user_message': 'Me gustan las películas de ciencia ficción.',\n",
       " 'chat_history': [HumanMessage(content='Hola, me llamo Andres Campos, Me recomiendas una película por favor.'),\n",
       "  AIMessage(content='¡Hola, Andrés! Claro que sí, ¿qué tipo de películas te gustan? ¿Prefieres algún género en particular o tienes alguna película favorita que te pueda ayudar a recomendarte algo similar? ¡Cuéntame un poco más para poder sugerirte una película adecuada para ti!'),\n",
       "  HumanMessage(content='Me gustan las películas de ciencia ficción.'),\n",
       "  AIMessage(content='¡Perfecto, las películas de ciencia ficción suelen ser muy interesantes! Te recomiendo la película \"Interestelar\" dirigida por Christopher Nolan. Esta película combina elementos de ciencia ficción con drama y exploración espacial de una manera muy intrigante. La trama gira en torno a un grupo de astronautas que viajan a través de un agujero de gusano en busca de un nuevo hogar para la humanidad. ¡Es una película visualmente impresionante y con una historia cautivadora! Espero que la disfrutes. ¡Cuéntame qué te pareció si decides verla!')],\n",
       " 'text': '¡Perfecto, las películas de ciencia ficción suelen ser muy interesantes! Te recomiendo la película \"Interestelar\" dirigida por Christopher Nolan. Esta película combina elementos de ciencia ficción con drama y exploración espacial de una manera muy intrigante. La trama gira en torno a un grupo de astronautas que viajan a través de un agujero de gusano en busca de un nuevo hogar para la humanidad. ¡Es una película visualmente impresionante y con una historia cautivadora! Espero que la disfrutes. ¡Cuéntame qué te pareció si decides verla!'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke({\"user_message\": \"Me gustan las películas de ciencia ficción.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Eres un buen chatbot teniendo una conversación con un humano.\n",
      "Human: Hola, me llamo Andres Campos, Me recomiendas una película por favor.\n",
      "AI: ¡Hola, Andrés! Claro que sí, ¿qué tipo de películas te gustan? ¿Prefieres algún género en particular o tienes alguna película favorita que te pueda ayudar a recomendarte algo similar? ¡Cuéntame un poco más para poder sugerirte una película adecuada para ti!\n",
      "Human: Me gustan las películas de ciencia ficción.\n",
      "AI: ¡Perfecto, las películas de ciencia ficción suelen ser muy interesantes! Te recomiendo la película \"Interestelar\" dirigida por Christopher Nolan. Esta película combina elementos de ciencia ficción con drama y exploración espacial de una manera muy intrigante. La trama gira en torno a un grupo de astronautas que viajan a través de un agujero de gusano en busca de un nuevo hogar para la humanidad. ¡Es una película visualmente impresionante y con una historia cautivadora! Espero que la disfrutes. ¡Cuéntame qué te pareció si decides verla!\n",
      "Human: Cual fue mi primera pregunta? Cual es mi nombre? Cual mi género favorito?\n",
      "        Dame tu respuesta en bullets.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'user_message': 'Cual fue mi primera pregunta? Cual es mi nombre? Cual mi género favorito?\\n        Dame tu respuesta en bullets.',\n",
       " 'chat_history': [HumanMessage(content='Hola, me llamo Andres Campos, Me recomiendas una película por favor.'),\n",
       "  AIMessage(content='¡Hola, Andrés! Claro que sí, ¿qué tipo de películas te gustan? ¿Prefieres algún género en particular o tienes alguna película favorita que te pueda ayudar a recomendarte algo similar? ¡Cuéntame un poco más para poder sugerirte una película adecuada para ti!'),\n",
       "  HumanMessage(content='Me gustan las películas de ciencia ficción.'),\n",
       "  AIMessage(content='¡Perfecto, las películas de ciencia ficción suelen ser muy interesantes! Te recomiendo la película \"Interestelar\" dirigida por Christopher Nolan. Esta película combina elementos de ciencia ficción con drama y exploración espacial de una manera muy intrigante. La trama gira en torno a un grupo de astronautas que viajan a través de un agujero de gusano en busca de un nuevo hogar para la humanidad. ¡Es una película visualmente impresionante y con una historia cautivadora! Espero que la disfrutes. ¡Cuéntame qué te pareció si decides verla!'),\n",
       "  HumanMessage(content='Cual fue mi primera pregunta? Cual es mi nombre? Cual mi género favorito?\\n        Dame tu respuesta en bullets.'),\n",
       "  AIMessage(content='- Tu primera pregunta fue si te podía recomendar una película.\\n- Tu nombre es Andrés Campos.\\n- Tu género favorito de películas es la ciencia ficción.')],\n",
       " 'text': '- Tu primera pregunta fue si te podía recomendar una película.\\n- Tu nombre es Andrés Campos.\\n- Tu género favorito de películas es la ciencia ficción.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(\n",
    "    {\n",
    "        \"user_message\": \"\"\"Cual fue mi primera pregunta? Cual es mi nombre? Cual mi género favorito?\n",
    "        Dame tu respuesta en bullets.\"\"\"\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOGMBpGzRJu0U7Lmu1TXxkD",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
